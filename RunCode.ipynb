{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from natsort import natsorted\n",
    "from nltk.corpus import stopwords \n",
    "import pandas as pd\n",
    "# nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "folder_names = [\"onFile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r', encoding =\"ascii\", errors =\"surrogateescape\") as f:\n",
    "        stuff = f.read()\n",
    " \n",
    "    f.close()\n",
    "     \n",
    "    return stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenze_and_remove_stopwords(final_string):\n",
    "    file_content = final_string\n",
    "    tokens_words = nltk.word_tokenize(file_content)\n",
    "    #print (tokens_words)\n",
    "    \n",
    "    #print words except \"in\" and \"to\" and \"where\"\n",
    "    tokenize_words_without_stopwords = []\n",
    "    for word in tokens_words:\n",
    "        if word.lower() not in stop_words:\n",
    "                tokenize_words_without_stopwords.append(word.lower())\n",
    "        elif word.lower() == \"in\"  or word.lower() == \"to\" or word.lower() == \"where\" in stop_words:\n",
    "                tokenize_words_without_stopwords.append(word.lower())\n",
    "    return (tokenize_words_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_indexing():\n",
    " \n",
    "    # Initialize the stemmer.\n",
    "    #stemmer = PorterStemmer()\n",
    "\n",
    "    # Initialize the file no.\n",
    "    fileno = 1\n",
    "\n",
    "    # Initialize the dictionary.\n",
    "    pos_index = {}\n",
    "\n",
    "    # Initialize the file mapping (fileno -> file name).\n",
    "    file_map = {}\n",
    "\n",
    "    for folder_name in folder_names:\n",
    "\n",
    "        # Open files.\n",
    "        file_names = natsorted(os.listdir(\"Files/\" + folder_name))\n",
    "\n",
    "        # For every file.\n",
    "        for file_name in file_names:\n",
    "\n",
    "            # Read file contents.\n",
    "            stuff = read_file(\"Files/\" + folder_name + \"/\" + file_name)\n",
    "\n",
    "            # This is the list of words in order of the text.\n",
    "            # We need to preserve the order because we require positions.\n",
    "            # 'preprocessing' function does some basic punctuation removal,\n",
    "            # stopword removal etc.\n",
    "            final_token_list = tokenze_and_remove_stopwords(stuff)\n",
    "            #print(final_token_list) \n",
    "            #بتطبع هنا واتاكد إن الفايلز شغالة تمام\n",
    "            # For position and term in the tokens.\n",
    "            for pos, term in enumerate(final_token_list):\n",
    "\n",
    "                        # First stem the term.\n",
    "                       # term = stemmer.stem(term)\n",
    "\n",
    "                        # If term already exists in the positional index dictionary.\n",
    "                        if term in pos_index:\n",
    "\n",
    "                            # Increment total freq by 1.\n",
    "                            pos_index[term][0] = pos_index[term][0] + 1\n",
    "\n",
    "                            # Check if the term has existed in that DocID before.\n",
    "                            if fileno in pos_index[term][1]:\n",
    "                                pos_index[term][1][fileno].append(pos+1)\n",
    "\n",
    "                            else:\n",
    "                                pos_index[term][1][fileno] = [pos+1]\n",
    "\n",
    "                        # If term does not exist in the positional index dictionary\n",
    "                        # (first encounter).\n",
    "                        else:\n",
    "\n",
    "                            # Initialize the list.\n",
    "                            pos_index[term] = []\n",
    "                            # The total frequency is 1.\n",
    "                            pos_index[term].append(1)\n",
    "                            # The postings list is initially empty.\n",
    "                            pos_index[term].append({})     \n",
    "                            # Add doc ID to postings list.\n",
    "                            pos_index[term][1][fileno] = [pos+1]\n",
    "\n",
    "            # Map the file no. to the file name.\n",
    "            file_map[fileno] = \"Files/\" + folder_name + \"/\" + file_name\n",
    "\n",
    "            # Increment the file no. counter for document ID mapping             \n",
    "            fileno += 1\n",
    "        \n",
    "        print(\"--------------------------------\")\n",
    "        print(\">>>>>> Positional Index <<<<<< \\n\")\n",
    "        print(\"Item: [ item frequancy, { files: [positions] } ] \\n\")\n",
    "        for x, y in pos_index.items():\n",
    "            print(x,y) #x y3ni term we y[0] y3ni el frequency \n",
    "        #return pos_index #lw 3awez arg3 el poitional index kolha mara w7da fe dict\n",
    "        print(\"--------------------------------\")\n",
    "        \n",
    "        # جزء الـ query اهووووووووووووووه\n",
    "        #sample_pos_idx = pos_index['mercy']\n",
    "       \n",
    "        #print(sample_pos_idx)\n",
    "        #file_list = sample_pos_idx[1]\n",
    "        #print(\"Filename, [Positions]\")\n",
    "        #for fileno, positions in file_list.items():\n",
    "        #    print(file_map[fileno], positions)\n",
    "        \n",
    "        query =input(\"Hello, Please insert your query:\")\n",
    "        \n",
    "        final_list =[ [] for i in range(10) ]\n",
    "        try:\n",
    "            for word in query.lower().split():\n",
    "                for key in pos_index[word][1].keys():\n",
    "                    if final_list[key-1] !=[]:\n",
    "                        if final_list[key-1][-1] == pos_index[word][1][key][0]-1:\n",
    "                            final_list[key-1].append(pos_index[word][1][key][0])\n",
    "                    else:\n",
    "                        final_list[key-1].append(pos_index[word][1][key][0])\n",
    "        except:\n",
    "            print(\"Not Exist!!\")\n",
    "        #print(final_list)\n",
    "        for position,inlist in enumerate(final_list, start=1):\n",
    "        #    print(position,inlist)\n",
    "            if len(inlist) == len(query.split()):\n",
    "                print(position)\n",
    "        return pos_index #lw 3awez arg3 el poitional index kolha mara w7da fe dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words After Tokenization! \n",
      "\n",
      "worser\n",
      "\n",
      "tread\n",
      "\n",
      "caeser\n",
      "\n",
      "where\n",
      "\n",
      "calpurnia\n",
      "\n",
      "to\n",
      "\n",
      "cleopatra\n",
      "\n",
      "fools\n",
      "\n",
      "in\n",
      "\n",
      "angels\n",
      "\n",
      "rush\n",
      "\n",
      "antony\n",
      "\n",
      "mercy\n",
      "\n",
      "brutus\n",
      "\n",
      "fear\n",
      "\n",
      "--------------------------------\n",
      ">>>>>> Positional Index <<<<<< \n",
      "\n",
      "Item: [ item frequancy, { files: [positions] } ] \n",
      "\n",
      "antony [3, {1: [1], 2: [1], 6: [1]}]\n",
      "brutus [3, {1: [2], 2: [2], 4: [1]}]\n",
      "caeser [5, {1: [3], 2: [3], 4: [2], 5: [1], 6: [2]}]\n",
      "cleopatra [1, {1: [4]}]\n",
      "mercy [5, {1: [5], 3: [1], 4: [3], 5: [2], 6: [3]}]\n",
      "worser [4, {1: [6], 3: [2], 4: [4], 5: [3]}]\n",
      "calpurnia [1, {2: [4]}]\n",
      "angels [3, {7: [1], 8: [1], 9: [1]}]\n",
      "fools [4, {7: [2], 8: [2], 9: [2], 10: [1]}]\n",
      "fear [3, {7: [3], 8: [3], 10: [2]}]\n",
      "in [4, {7: [4], 8: [4], 9: [3], 10: [3]}]\n",
      "rush [4, {7: [5], 8: [5], 9: [4], 10: [4]}]\n",
      "to [4, {7: [6], 8: [6], 9: [5], 10: [5]}]\n",
      "tread [4, {7: [7], 8: [7], 9: [6], 10: [6]}]\n",
      "where [4, {7: [8], 8: [8], 9: [7], 10: [7]}]\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hello, Please insert your query: in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "============================================================================================================                                                    \n",
      "This is term frequency\n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "angels        0     0     0     0     0     0     1     1     1      0\n",
      "antony        1     1     0     0     0     1     0     0     0      0\n",
      "brutus        1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "fools         0     0     0     0     0     0     1     1     1      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "mercy         1     0     1     1     1     1     0     0     0      0\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "worser        1     0     1     1     1     0     0     0     0      0 \n",
      "\n",
      "============================================================================================================                                                    \n",
      "Weighted term frequency =log(tf)+1\n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "angels        0     0     0     0     0     0     1     1     1      0\n",
      "antony        1     1     0     0     0     1     0     0     0      0\n",
      "brutus        1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "fools         0     0     0     0     0     0     1     1     1      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "mercy         1     0     1     1     1     1     0     0     0      0\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "worser        1     0     1     1     1     0     0     0     0      0 \n",
      "\n",
      "============================================================================================================                                                    \n",
      "inverse document frequency\n",
      "\n",
      "          df       idf\n",
      "angels     3  0.522879\n",
      "antony     3  0.522879\n",
      "brutus     3  0.522879\n",
      "caeser     5   0.30103\n",
      "calpurnia  1         1\n",
      "cleopatra  1         1\n",
      "fear       3  0.522879\n",
      "fools      4   0.39794\n",
      "in         4   0.39794\n",
      "mercy      5   0.30103\n",
      "rush       4   0.39794\n",
      "to         4   0.39794\n",
      "tread      4   0.39794\n",
      "where      4   0.39794\n",
      "worser     4   0.39794\n",
      "============================================================================================================                                                    \n",
      "tf-idf\n",
      "\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "angels            0         0        0         0        0         0  0.522879   \n",
      "antony     0.522879  0.522879        0         0        0  0.522879         0   \n",
      "brutus     0.522879  0.522879        0  0.522879        0         0         0   \n",
      "caeser      0.30103   0.30103        0   0.30103  0.30103   0.30103         0   \n",
      "calpurnia         0         1        0         0        0         0         0   \n",
      "cleopatra         1         0        0         0        0         0         0   \n",
      "fear              0         0        0         0        0         0  0.522879   \n",
      "fools             0         0        0         0        0         0   0.39794   \n",
      "in                0         0        0         0        0         0   0.39794   \n",
      "mercy       0.30103         0  0.30103   0.30103  0.30103   0.30103         0   \n",
      "rush              0         0        0         0        0         0   0.39794   \n",
      "to                0         0        0         0        0         0   0.39794   \n",
      "tread             0         0        0         0        0         0   0.39794   \n",
      "where             0         0        0         0        0         0   0.39794   \n",
      "worser      0.39794         0  0.39794   0.39794  0.39794         0         0   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "angels     0.522879  0.522879         0  \n",
      "antony            0         0         0  \n",
      "brutus            0         0         0  \n",
      "caeser            0         0         0  \n",
      "calpurnia         0         0         0  \n",
      "cleopatra         0         0         0  \n",
      "fear       0.522879         0  0.522879  \n",
      "fools       0.39794   0.39794   0.39794  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "mercy             0         0         0  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "worser            0         0         0  \n",
      "============================================================================================================                                                    \n",
      "Document length\n",
      "\n",
      "\n",
      "         doc1_length  doc2_length  doc3_length  doc4_length  doc5_length  \\\n",
      "length     1.373462     1.279618     0.498974     0.782941     0.582747   \n",
      "\n",
      "        doc6_length  doc7_length  doc8_length  doc9_length  doc10_length  \n",
      "length      0.67427     1.223496     1.223496     1.106137      1.106137  \n",
      "============================================================================================================                                                    \n",
      "Normalized tf-idf\n",
      "\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "angels     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "antony     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
      "brutus     0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fools      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "mercy      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "angels     0.427365  0.427365  0.472707  0.000000  \n",
      "antony     0.000000  0.000000  0.000000  0.000000  \n",
      "brutus     0.000000  0.000000  0.000000  0.000000  \n",
      "caeser     0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
      "fear       0.427365  0.427365  0.000000  0.472707  \n",
      "fools      0.325248  0.325248  0.359756  0.359756  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "mercy      0.000000  0.000000  0.000000  0.000000  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n",
      "worser     0.000000  0.000000  0.000000  0.000000  \n",
      "============================================================================================================                                                    \n",
      "Result \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter query ,please:\n",
      " antony brutus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query\n",
      "         tf  w_tf       idf    tf_idf      norm\n",
      "antony   1   1.0  0.522879  0.522879  0.707107\n",
      "brutus   1   1.0  0.522879  0.522879  0.707107\n",
      "\n",
      "query length :\n",
      " 0.7394622130520805\n",
      "\n",
      "product (query*match doc)\n",
      "\n",
      "             doc1      doc2\n",
      "antony  0.269196  0.288939\n",
      "brutus  0.269196  0.288939\n",
      "\n",
      "product sum\n",
      "doc1    0.538393\n",
      "doc2    0.577877\n",
      "dtype: float64\n",
      "\n",
      "cosine similarity:\n",
      "doc1    0.538393\n",
      "doc2    0.577877\n",
      "dtype: float64\n",
      "\n",
      "returned docs\n",
      "doc2 doc1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "sett={}\n",
    "sett=set(sett)\n",
    "Documents=[]\n",
    "print(\"Words After Tokenization! \\n\")\n",
    "for folder_name in folder_names:\n",
    " \n",
    "    # Open files.\n",
    " \n",
    "    file_names = natsorted(os.listdir(\"Files/\" + folder_name))\n",
    " \n",
    "    # For every file.\n",
    "    for file_name in file_names:\n",
    " \n",
    "        # Read file contents.\n",
    "        stuff = read_file(\"Files/\" + folder_name + \"/\" + file_name)\n",
    "        \n",
    "        # This is the list of words in order of the text.\n",
    "        # We need to preserve the order because we require positions.\n",
    "        # 'preprocessing' function does some basic punctuation removal,\n",
    "        # stopword removal etc.\n",
    "        final_token_list = tokenze_and_remove_stopwords(stuff) \n",
    "        Documents.append(final_token_list)# \n",
    "        for word in final_token_list:\n",
    "            if word not in sett:\n",
    "                sett.add(word) #dh elly feh el tokens\n",
    "#print(Documents)     #--> list of documents that were toknized <-- dh elly feh tokens of files            \n",
    "for word in sett:\n",
    "    print(word+\"\\n\")\n",
    "# #pos_index = positional_indexing()\n",
    "# #for x, y in pos_index.items():\n",
    "# #        print(x, y)\n",
    "PosIndexing = positional_indexing() #el positional index \n",
    "all_words=[]\n",
    "for doc in Documents:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    "\n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word] +=1\n",
    "    return dict(sorted(words_found.items()))\n",
    "term_freq=pd.DataFrame(get_term_freq(Documents[0]).values(),index=get_term_freq(Documents[0]).keys())\n",
    "for i in range(1,len(Documents)):\n",
    "    term_freq[i]=get_term_freq(Documents[i]).values()\n",
    "term_freq.columns=['doc'+str(i) for i in range(1,11)]\n",
    "print('='*108,' '*50,'\\nThis is term frequency\\n')\n",
    "print(term_freq,\"\\n\")\n",
    "def get_weighted_term_freq(x):\n",
    "    if x> 0:\n",
    "        return int(math.log(x) +1)\n",
    "    return 0\n",
    "\n",
    "print('='*108,' '*50,'\\nWeighted term frequency =log(tf)+1\\n')\n",
    "for i in range(1,len(Documents)+1):\n",
    "    term_freq['doc'+str(i)]=term_freq['doc'+str(i)].apply(get_weighted_term_freq)\n",
    "print(term_freq,\"\\n\")\n",
    "print('='*108,' '*50,'\\ninverse document frequency\\n')\n",
    "tfd=pd.DataFrame(columns=('df','idf'))\n",
    "for i in range(len(term_freq)):\n",
    "    frequency=term_freq.iloc[i].values.sum() # (iloc) btgib el position bta3 elklma fe eldataframe\n",
    "    tfd.loc[i,'df']=frequency\n",
    "    tfd.loc[i,'idf']=math.log10(10/ float(frequency))\n",
    "\n",
    "tfd.index=term_freq.index\n",
    "print(tfd)\n",
    "\n",
    "print('='*108,' '*50,'\\ntf-idf\\n')\n",
    "term_freq_inve_doc_freq=term_freq.multiply(tfd['idf'],axis=0)\n",
    "print(term_freq_inve_doc_freq)\n",
    "print('='*108,' '*50,'\\nDocument length\\n')\n",
    "document_length=pd.DataFrame()\n",
    "def get_docs_length(col):\n",
    "    return np.sqrt(term_freq_inve_doc_freq[col].apply(lambda x:x**2).sum())\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    document_length.loc['length',column+'_length']=get_docs_length(column)\n",
    "\n",
    "print('\\n',document_length)\n",
    "print('='*108,' '*50,'\\nNormalized tf-idf\\n')\n",
    "normalized_term_freq_idf=pd.DataFrame()\n",
    "def get_normalized(col,x):\n",
    "    try:\n",
    "        return x / document_length[col+'_length'].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "for column in term_freq_inve_doc_freq.columns:   \n",
    "    normalized_term_freq_idf[column] =term_freq_inve_doc_freq[column].apply(lambda x: get_normalized(column,x)) \n",
    "\n",
    "print(normalized_term_freq_idf)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
